{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import (HumanMessage,SystemMessage)\n",
    "\n",
    "\n",
    "default_ef = embedding_functions.DefaultEmbeddingFunction()\n",
    "client = chromadb.PersistentClient(path=\"contexts\")\n",
    "db = client.get_collection(\"daniel\", embedding_function=default_ef)\n",
    "llm = ChatOpenAI(model=\"gpt-4-1106-preview\")\n",
    "\n",
    "def context_search(question):\n",
    "    context = db.query(query_texts=question, n_results=2,)\n",
    "    print(\"Using \", context['documents'])\n",
    "    return context['documents']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "messages = [SystemMessage(content=f'''\n",
    "You are an helpful AI Assistant who is designed to tell user the life story of Daniel and\n",
    "answer questions about him, use the context provided to answer the question.\n",
    "''')]\n",
    "\n",
    "def get_response(question):\n",
    "    input_message = f'''Here is the context: {context_search(question)} and this is the question {question}'''\n",
    "    messages.append(input_message)\n",
    "    response = llm.invoke(messages)\n",
    "    messages.append(response)\n",
    "    return response.content\n",
    "\n",
    "\n",
    "def get_response_2(question):\n",
    "    if question.lower() == \"hy\":\n",
    "        input_message = question\n",
    "    else:        \n",
    "        input_message = f'''Here is the context: {context_search(question)} and this is the question {question}'''\n",
    "    messages.append(input_message)\n",
    "    response = llm.invoke(messages)\n",
    "    messages.append(response)\n",
    "    return response.content\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Hello! It looks like you might have a question or topic in mind regarding Daniel's life story. Feel free to share more details or ask a question, and I'll do my best to assist you!\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    question = input(\"You: \")\n",
    "    if question == \"exit\":\n",
    "        break\n",
    "    answer = get_response_2(question)\n",
    "    print(f\"AI: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='\\nYou are an helpful AI Assistant who is designed to tell user the life story of Daniel and\\nanswer questions about him, use the context provided to answer the question.\\n'),\n",
       " \"Here is the context: [['Daniel is 45 years old', 'Daniel is a developer']] and this is the question how old is Daniel\",\n",
       " AIMessage(content='Daniel is 45 years old.', response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 73, 'total_tokens': 80}, 'model_name': 'gpt-4-1106-preview', 'system_fingerprint': 'fp_6bc7cb96fb', 'finish_reason': 'stop', 'logprobs': None}, id='run-41405233-88cf-4dd7-8bab-70a96955c205-0'),\n",
       " \"Here is the context: [['Daniel works in tech', 'Daniel is a developer']] and this is the question What does he do?\",\n",
       " AIMessage(content='Daniel is a developer.', response_metadata={'token_usage': {'completion_tokens': 5, 'prompt_tokens': 115, 'total_tokens': 120}, 'model_name': 'gpt-4-1106-preview', 'system_fingerprint': 'fp_89f117abc5', 'finish_reason': 'stop', 'logprobs': None}, id='run-6fad66ce-9bf8-4e62-bc20-e5599548bcd1-0'),\n",
       " \"Here is the context: [['Daniel is a developer', 'Daniel is 45 years old']] and this is the question \",\n",
       " \"Here is the context: [['Daniel is 45 years old', 'Daniel works in tech']] and this is the question How old is dan\",\n",
       " AIMessage(content='Daniel is 45 years old.', response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 185, 'total_tokens': 192}, 'model_name': 'gpt-4-1106-preview', 'system_fingerprint': 'fp_6bc7cb96fb', 'finish_reason': 'stop', 'logprobs': None}, id='run-dee4d993-ee19-476d-a414-61641f880568-0')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
