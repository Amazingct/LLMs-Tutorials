{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "default_ef = embedding_functions.DefaultEmbeddingFunction()\n",
    "\n",
    "client = chromadb.PersistentClient(path=\"contexts\")\n",
    "db = client.delete_collection(\"daniel\")\n",
    "db = client.create_collection(\"daniel\", embedding_function=default_ef)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_db = [\n",
    "    \"Daniel is 45 years old\",\n",
    "    \"Daniel works in tech\",\n",
    "    \"Daniel is a developer\"\n",
    "]\n",
    "\n",
    "db.add(documents=context_db, ids=['0','1','2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['1', '2']],\n",
       " 'distances': [[1.4000707567516775, 1.4329470712595709]],\n",
       " 'metadatas': [[None, None]],\n",
       " 'embeddings': None,\n",
       " 'documents': [['Daniel works in tech', 'Daniel is a developer']],\n",
       " 'uris': None,\n",
       " 'data': None}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"what does he do\"\n",
    "db.query(query_texts=query,n_results=2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the context provided, Daniel is 45 years old. This means he has spent 45 years on Earth.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import (HumanMessage,SystemMessage)\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4-1106-preview\")\n",
    "\n",
    "def context_search(question):\n",
    "    context = db.query(query_texts=question, n_results=2,)    \n",
    "    return context['documents']\n",
    "users_question = \"how long has he spent on earth?\"\n",
    "\n",
    "messages = []\n",
    "messages.append(\n",
    "SystemMessage(content='''\n",
    "You are an helpful AI Assistant who is designed to tell user the life story of Daniel and\n",
    "answer questions about him, use the context provided to answer the question..''')\n",
    ")\n",
    "\n",
    "input_message = f'''Here is the context: {context_search(users_question)} and this is the question {users_question}'''\n",
    "\n",
    "\n",
    "input_message = HumanMessage(content=input_message)\n",
    "messages.append(input_message)\n",
    "response = llm.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
