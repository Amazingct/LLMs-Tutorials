{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "SET UP CONDA ENVIRONMENT:\n",
    "conda create -n llms python=3.11\n",
    "conda activate llms\n",
    "pip install -r requirements.txt\n",
    "'''\n",
    "import os\n",
    "# os.environ[\"OPEN_AI_API\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4-1106-preview\")\n",
    "llm2 = Ollama(model=\"llama2\") #Free but not as efficient as gpt4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "messages.append(\n",
    "    SystemMessage(content=\"You are an helpful AI Assistant\")\n",
    ")\n",
    "input_message = HumanMessage(content=\"Who is Daniel?\")\n",
    "messages.append(input_message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.invoke(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "- Expensive\n",
    "- Context Window\n",
    "- Slow\n",
    "- Unnecessary Information (user might only be intrested in age etc)\n",
    "'''\n",
    "\n",
    "messages = []\n",
    "messages.append(\n",
    "    SystemMessage(content='''\n",
    "                  \n",
    "                  You are an helpful AI Assistant who is designed to tell user the life story of Daniel and\n",
    "                  answer questions about him.\n",
    "                  \n",
    "                  Context:\n",
    "                  Daniel is an AI and IoT engineer, He is 40 years old and he works for Google\n",
    "                  \n",
    "                  ''')\n",
    ")\n",
    "input_message = HumanMessage(content=\"Who does dan do?\")\n",
    "messages.append(input_message)\n",
    "response = llm.invoke(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_db = [\n",
    "    \"Daniel is 45 years old\",\n",
    "    \"Daniel works in tech\"\n",
    "    \"Daniel is a developer\"\n",
    "]\n",
    "\n",
    "users_question = \"How old is Daniel\"\n",
    "\n",
    "messages = []\n",
    "messages.append(\n",
    "    SystemMessage(content='''\n",
    "                  You are an helpful AI Assistant who is designed to tell user the life story of Daniel and\n",
    "                  answer questions about him, use the context provided to answer the question..\n",
    "                  ''')\n",
    ")\n",
    "\n",
    "input_message = f''' Here is the context: {context_db[0]} and this is the question {users_question}'''\n",
    "\n",
    "\n",
    "input_message = HumanMessage(content=input_message)\n",
    "messages.append(input_message)\n",
    "response = llm.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_db = [\n",
    "    \"Daniel is 45 years old\",\n",
    "    \"Daniel works in tech\"\n",
    "    \"Daniel is a developer\"\n",
    "]\n",
    "\n",
    "def context_search(context_list, question):\n",
    "    for context in context_list:\n",
    "        if any(word in context for word in question.split()):\n",
    "            print(\"Using: \", context)\n",
    "            return context\n",
    "\n",
    "users_question = \"how long has he spent on earth?\"\n",
    "\n",
    "messages = []\n",
    "messages.append(\n",
    "SystemMessage(content='''\n",
    "You are an helpful AI Assistant who is designed to tell user the life story of Daniel and\n",
    "answer questions about him, use the context provided to answer the question..''')\n",
    ")\n",
    "\n",
    "input_message = f'''Here is the context: {context_search(context_db, users_question)} and this is the question {users_question}'''\n",
    "\n",
    "\n",
    "input_message = HumanMessage(content=input_message)\n",
    "messages.append(input_message)\n",
    "response = llm.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
